{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1d0ddf-6a18-468f-ac49-6d7858a8e71f",
   "metadata": {},
   "source": [
    "## Preprocessing des Datensatzes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044723c2-08e3-4189-9e0f-d6f2744249ff",
   "metadata": {},
   "source": [
    "### Laden der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e2e4e-011a-4f1e-b475-179d5f6d0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Geofencing Bibliotheken\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4554a-7048-4368-a998-632a5e1c9780",
   "metadata": {},
   "source": [
    "### Einlesen des Datensatzes\n",
    "Dateiname des Datensatzes: Maschen_211207_TUDA_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d23284-3fea-4c92-a439-7e9fcbc49133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zur CSV Datei \n",
    "pathMaschen = os.path.join(\"..\", \"..\", \"data\", \"Maschen_211207_TUDA_data.csv\")\n",
    "# importieren des Datensatzes in einen pd DataFrame\n",
    "dfMaschen = pd.read_csv(pathMaschen)\n",
    "dfMaschen = dfMaschen.sort_values(by=['wagon_ID','timestamp_measure_position'])\n",
    "#dfMaschen = dfMaschen.head(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4388e3f3-a0a3-46fe-a7e1-03f8a6a19e46",
   "metadata": {},
   "source": [
    "### Formatieren des Datensatzes / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12abf7-76b0-428a-ba26-2c947451bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeitpunkte aus Strings in Sekunden formatieren\n",
    "def format_timestamp(timestamp_string: str) -> float:\n",
    "    \"\"\"\n",
    "    Funktion, die aus dem timestamp_string einen float in sekunden zurückgibt\n",
    "    :param timestamp_string: Zeitstempel\n",
    "    :return: float: Zeit in Sekunden\n",
    "    \"\"\"\n",
    "    string_list_leerzeichen = timestamp_string.split(' ')\n",
    "    days = float(string_list_leerzeichen[0])\n",
    "    days_in_sec = days * 24 * 60 * 60\n",
    "    string_list_doppelpunkt = string_list_leerzeichen[-1].split(':')\n",
    "    hours = float(string_list_doppelpunkt[0])\n",
    "    hours_in_sec = hours * 60 * 60\n",
    "    minutes = float(string_list_doppelpunkt[1])\n",
    "    minutes_in_sec = minutes * 60\n",
    "    sec_in_sec = float(string_list_doppelpunkt[2])\n",
    "    total_time_in_sec = days_in_sec + hours_in_sec + minutes_in_sec + sec_in_sec\n",
    "    return total_time_in_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a01420-6bc9-4480-82d8-35ea49bd595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfMaschen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a90a3-49de-429a-9d25-45cd77f5ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp_measure_position mit NaN wird bereinigt (Nat in dieser Csv für timestmap_measure_position nicht vorhanden)\n",
    "dfMaschen.drop(dfMaschen.loc[dfMaschen['timestamp_measure_position']=='NaT'].index, inplace=True)\n",
    "print(len(dfMaschen))\n",
    "\n",
    "# Anwenden der Funktion format_timestamp\n",
    "dfMaschen['timestamp_measure_position'] = dfMaschen['timestamp_measure_position'].apply(format_timestamp) \n",
    "\n",
    "# Codieren des \"movement_state\" in integer: \"moving\"=2, \"standing\"=1, \"parking\"=0\n",
    "# Codieren als String Operations\n",
    "dfMaschen['movement_state'].replace('moving', '2', inplace=True, regex=True)\n",
    "dfMaschen['movement_state'].replace('standing', '1', inplace=True, regex=True)\n",
    "dfMaschen['movement_state'].replace('parking', '0', inplace=True, regex=True)\n",
    "# Konvertierung von String zu float (str->float; anstatt int, da NaN für den Typ int nicht erlaubt ist)\n",
    "dfMaschen.movement_state = dfMaschen.movement_state.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb293151-6e4a-4274-be9d-0b2b895a66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Werte, die außerhalb des Geofences um den Maschen Bahnhof liegen entfernen\n",
    "# Punkte für ein Polygon um den Maschenbahnhof\n",
    "\n",
    "# exaktes Polygon um Maschen\n",
    "'''polygonPunkteMaschen = np.array([\n",
    "    [53.391718, 10.087218],\n",
    "    [53.393941, 10.072218],\n",
    "    [53.397919, 10.059582],\n",
    "    [53.406176, 10.047843],\n",
    "    [53.406176, 10.047843],\n",
    "    [53.424749, 10.027210],\n",
    "    [53.424608, 10.030620],\n",
    "    [53.418648, 10.039877],\n",
    "    [53.414849, 10.048505],\n",
    "    [53.412179, 10.053845],\n",
    "    [53.409576, 10.057802],\n",
    "    [53.404956, 10.064698],\n",
    "    [53.397338, 10.080605],\n",
    "    [53.392461, 10.096895],\n",
    "    [53.388525, 10.096012]\n",
    "])\n",
    "'''\n",
    "\n",
    "# grobes Polygon um Maschen\n",
    "polygonPunkteMaschen = np.array([\n",
    "    [53.430275, 10.03927],\n",
    "    [53.422016, 10.020830],\n",
    "    [53.398547, 10.035114],\n",
    "    [53.386725, 10.089851], \n",
    "    [53.397499, 10.103144],\n",
    "    [53.417347, 10.075169]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff439910-179c-465b-ae37-a7c1ac910502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon erstellen mit den Punkten um den Maschenbahnhof\n",
    "polygonMaschen = Polygon(polygonPunkteMaschen)\n",
    "polygonMaschen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad72806-a8cc-41f4-8375-0525428b2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCoordinateInMaschen(row):\n",
    "    \"\"\"\n",
    "    Funktion, die für eine Reihe prüft, ob die Koordinaten im Maschenbahnhof liegen oder nicht\n",
    "    :param row: Reihe eines pandas DataFrame\n",
    "    :return: Reihe eines pandas DataFrame mit zusätzlicher Spalte (bool), ob Punkt im\n",
    "             Maschen Bahnhof liegt\n",
    "    \"\"\"\n",
    "    lat = row['latitude']\n",
    "    long = row['longitude']\n",
    "    point = Point(lat, long)\n",
    "    # Überprüfen, ob der Punkt in Maschen liegt\n",
    "    boolPoint = point.within(polygonMaschen)\n",
    "    row['is_in_maschen'] = boolPoint\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b6066-9e3d-45df-95c8-34ff41c64fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfMaschen))\n",
    "\n",
    "# Die Funktion \"isCoordinateInMaschen\" wird auf den DataFrame angewendet\n",
    "dfMaschen = dfMaschen.apply(isCoordinateInMaschen, axis=1)\n",
    "\n",
    "# dfMaschenMapping = dfMaschenMapping[dfMaschenMapping.is_in_maschen]\n",
    "dfMaschen = dfMaschen[dfMaschen['is_in_maschen']==1]\n",
    "dfMaschen.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(len(dfMaschen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45e2d5-b449-41e2-b5e9-4e68f01d60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# wagonID2Plot 1017603201772777\n",
    "\n",
    "# Überblick durch Geodaten und the wagon moving state\"\n",
    "wagonIDList = np.sort(dfMaschen[\"wagon_ID\"].drop_duplicates().to_numpy())\n",
    "\n",
    "from random import randrange\n",
    "radn_ind = randrange(len(wagonIDList))\n",
    "\n",
    "if 1:\n",
    "    wagonID2Plot = wagonIDList[radn_ind]\n",
    "    print(wagonID2Plot)\n",
    "else: \n",
    "    wagonID2Plot =1017603204104556\n",
    "    print(wagonID2Plot)\n",
    "    \n",
    "\n",
    "map_maschen = plt.imread(os.path.join('..', '..', 'data', 'map.png'))\n",
    "BBox = (10.0208, 10.1031, 53.3867, 53.4303)\n",
    "\n",
    "\n",
    "Y = dfMaschen[dfMaschen[\"wagon_ID\"] == wagonID2Plot]\n",
    "X = Y.sort_values(by=['timestamp_measure_position'])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize = (7,4.666), constrained_layout=True, sharey=True)\n",
    "ax[0].plot(X['longitude'],\n",
    "           X['latitude'], color='blue', zorder=1, linewidth=0.5)\n",
    "ax[0].scatter(X['longitude'],\n",
    "           X['latitude'], s = 6, c = X['timestamp_measure_position'], cmap='Blues', zorder=2, marker='.')\n",
    "\n",
    "\n",
    "for axes in ax:\n",
    "    axes.set_xlim(BBox[0], BBox[1])\n",
    "    axes.set_ylim(BBox[2], BBox[3])\n",
    "    axes.imshow(map_maschen, extent= BBox, zorder=0, aspect='equal')\n",
    "    axes.set_aspect(1.5)\n",
    "    axes.grid(False)\n",
    "\n",
    "ax[0].set_xlabel('Longitude (Breitengrad)', fontsize = 15)\n",
    "ax[1].set_xlabel('Longitude (Breitengrad)', fontsize = 15)\n",
    "\n",
    "ax[0].set_ylabel('Latitude (Lägengrad)', fontsize = 15)\n",
    "\n",
    "fig.savefig(os.path.join('..', 'doc', 'wagonID.pdf'))\n",
    "\n",
    "\n",
    "inDHMS = list(np.ones(len(X)))\n",
    "\n",
    "# timestamp Sekunden in Tage Stunden etc umrechnen \n",
    "import datetime \n",
    "  \n",
    "def convert(n): \n",
    "    return str(datetime.timedelta(seconds = n))\n",
    "\n",
    "\n",
    "\n",
    "for ii, time in enumerate(X['timestamp_measure_position'].values):\n",
    "    inDHMS[ii] = convert(time)\n",
    "\n",
    "X.loc[:,'time_position'] = inDHMS\n",
    "    \n",
    "print(X[['movement_state','time_position' ]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20249921-1eb9-4ee2-a08c-6c990d4c1cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d2127b-80d4-4ed7-909b-f707a8b18169",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaschen[\"wagon_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dac362-c853-4d5a-ae7f-c95cd855e6cd",
   "metadata": {},
   "source": [
    "## Create list in which in every row a df for every single Ride is stored\n",
    "\n",
    "List is called: **list_splitRide**\n",
    "\n",
    "ein _ride_ ist folgend definiert: \n",
    "- zwischen zwei Zustandspunkten liegt mindestens ein Zeitabstand von 2 Stunden vor\n",
    "- der _movement_state_ ist nicht parken (da hier die 2 Stunden regulär überschritten werden dürfen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbecf1e-1362-48aa-bcff-f96afecabdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.mode.chained_assignment = None  # default='warn'\n",
    "dfMaschen['wagon_ID'].replace('\\'', '', inplace=True, regex=True)\n",
    "# Strings werden in integer umgewandelt\n",
    "dfMaschen.wagon_ID = dfMaschen.wagon_ID.astype('int64')     #int64 damit Funktionalität auch für OS = Windows\n",
    "wagon_IDList = np.sort(dfMaschen[\"wagon_ID\"].drop_duplicates().to_numpy())\n",
    "dfMaschen_md = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for ii, wagon_ID in enumerate(wagon_IDList):\n",
    "    # df erst nach wagon_ID sortiert, dann jede einzelne wagon_Id nochmals nach der Zeit\n",
    "    df_ID = dfMaschen[dfMaschen['wagon_ID'] == wagon_ID]\n",
    "    df_ID_sort = df_ID.sort_values(by=['timestamp_measure_position'])\n",
    "    \n",
    "    # einzelnen Wagendaten aufteilen nach Fahrten (einzelne Fahrten in Maschen)\n",
    "    diff_time = df_ID_sort['timestamp_measure_position'].diff()\n",
    "    diff_time.drop(index=diff_time.index[0], axis=0, inplace=True) # erster Eintrag löschen, um die Zeitdifferenz um ein Element nach vorne zu schieben\n",
    "    diff_time = diff_time.append(pd.Series(data=[0])) # damit der Vektor wieder die richtige Länge besitzt\n",
    "    diff_time = diff_time.reset_index(drop=True)\n",
    "    \n",
    "    # fillna(ffill) füllt alle NaN Werte mit dem letzten nicht NaN Werte auf\n",
    "    # wird bennötig, da Movement State Event Message --> wird nur bei einer Änderung betätigt\n",
    "    df_ID_sort['movement_state'] = df_ID_sort['movement_state'].fillna(method=\"ffill\")\n",
    "    df_ID_sort = df_ID_sort.reset_index(drop=True)\n",
    "    \n",
    "    # Zeilen finden, bei denen der Zeitabstand größer als 2 Stunden ist (d.h. der Wagon hat Maschen verlassen und ist zu einem späteren Zeitpunkt wieder eingefahren)\n",
    "    single_ride = np.array(np.ones(len(diff_time))-1)\n",
    "    single_ride[diff_time > 20*60] = 1 # eine 1 beschreibt, dass dies der letzte Eintrag einer Fahrt ist\n",
    "    \n",
    "    \n",
    "    single_ride[(diff_time > 20*60) & (diff_time < 24.1*60*60) & (df_ID_sort['movement_state'] == 0)] = 0 # da wenn der Wagon parkt auch ein die Zeitdifferenz überschritten würde \n",
    "    ind_Ride_end = np.where(single_ride == 1)[0]\n",
    "    \n",
    "    # ind_Ride_start: # der Wert enspricht dem Index des ersten Eintrags einer neuen Fahrt\n",
    "    ind_Ride_start = ind_Ride_end + 1 # ind_Ride gibt ab hier die Position einer neuen Fahrt an\n",
    "    ind_Ride_start = np.append(np.array(0),ind_Ride_start) # um for_Schleife zu vereinfachen wird erste Position des Vektors auch abgespeichert\n",
    "    ind_Ride_start = np.append(ind_Ride_start,np.array(len(diff_time))) # die letzte Zahl ist 1 höher als es Positinen gibt, damit pos_movState_0 einfacher ermittelt werden kann\n",
    "\n",
    "    df_ID_sort['Ride'] = -1\n",
    "    \n",
    "    for ll, ind in enumerate(ind_Ride_start):\n",
    "\n",
    "        if ll < len(ind_Ride_start)-1: # because otherwise ll+1 would cause an error\n",
    "            df_ID_sort['Ride'][ind:ind_Ride_start[ll+1]] = count\n",
    "            count += 1\n",
    "        else: \n",
    "            df_ID_sort.loc[['Ride'][ind:]] = count\n",
    "            count += 1\n",
    "        #moveCountWagon = np.append(moveCountWagon,movement_count)\n",
    "\n",
    "    # wieder zu einem großen df zusammenfügen\n",
    "    dfMaschen_md = dfMaschen_md.append(df_ID_sort)\n",
    "    \n",
    "dfMaschen = dfMaschen_md\n",
    "print(len(dfMaschen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1db7d-6938-4df0-9bf8-8fd360323c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RideList 3335, 3765, 1619, 4839, 3587, 349, 4000, 5168, mit 0.5: 3836, 4925 mit 20min: 7490 4529\n",
    "\n",
    "# Überblick durch Geodaten und the wagon moving state\"\n",
    "RideList = np.sort(dfMaschen[\"Ride\"].drop_duplicates().to_numpy())\n",
    "\n",
    "from random import randrange\n",
    "radn_ind = randrange(len(RideList))\n",
    "\n",
    "if 0:\n",
    "    Ride2Plot = RideList[radn_ind]\n",
    "else: Ride2Plot = 2903\n",
    "\n",
    "X = dfMaschen[dfMaschen[\"Ride\"] == Ride2Plot]\n",
    "\n",
    "#X = X[X['signal_quality_hdop']<3]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10,10))\n",
    "ax.scatter(X['longitude'],\n",
    "           X['latitude'],\n",
    "           c = X['timestamp_measure_position'], s = 20)\n",
    "\n",
    "ax.plot(X['longitude'],\n",
    "           X['latitude'])\n",
    "\n",
    "ax.set_xlabel('longitude', fontsize = 15)\n",
    "ax.set_ylabel('latitude', fontsize = 15)\n",
    "ax.set_title('Beispielfahrt von Ride '+str(Ride2Plot)+ ' mit gezeigtem movement_count', fontsize = 20)  \n",
    "ax.scatter(polygonPunkteMaschen[:,1],polygonPunkteMaschen[:,0],marker='x')\n",
    "plt.show()\n",
    "\n",
    "inDHMS = list(np.ones(len(X)))\n",
    "\n",
    "# timestamp Sekunden in Tage Stunden etc umrechnen \n",
    "import datetime \n",
    "  \n",
    "def convert(n): \n",
    "    return str(datetime.timedelta(seconds = n))\n",
    "\n",
    "\n",
    "\n",
    "for ii, time in enumerate(X['timestamp_measure_position'].values):\n",
    "    inDHMS[ii] = convert(time)\n",
    "\n",
    "X.loc[:,'time_position'] = inDHMS\n",
    "    \n",
    "print(X[['wagon_ID','movement_state','time_position' ]].head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d5222-e35a-43da-a3cd-38bf8c2994c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import Counter\n",
    "#Counter(dfMaschen['Ride'])\n",
    "#dfMaschen_md[['Ride','timestamp_measure_position','wagon_ID']].tail(50)\n",
    "#dfMaschen_md['Ride'].iloc[0]\n",
    "#ind_Ride_start\n",
    "#len(diff_time)\n",
    "#diff_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40823ef-ebd4-42d3-960c-a421fe8f22e8",
   "metadata": {},
   "source": [
    "#### !!!Überprüfen, ob timestamp_measure_movement_state nahe an timestamp_measure_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea82ff-0dc3-4487-9f9f-1a8c731093b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dfMaschen))\n",
    "# Reihen, die beim cleaning von NaN ignoriert werden\n",
    "cols_to_ignore = ['timestamp_measure_movement_state']\n",
    "searchInCols = [x for x in dfMaschen.columns.tolist() if x not in cols_to_ignore]\n",
    "# Reihen mit NaN werden bereinigt (außer die NaN ist in einer der \"cols_to_ignore\"\n",
    "dfMaschen.dropna(subset=searchInCols, axis=0)\n",
    "print(len(dfMaschen))\n",
    "\n",
    "# Altitude muss eigenständig / anders behandelt werden, da dort Datentyp: \"numpy.float64\"\n",
    "# wodurch ein \"nan\" anstatt \"NaN\"\n",
    "### dfMaschen = dfMaschen[dfMaschen['altitude'].notna()]\n",
    "# Zurücksetzen des Index\n",
    "dfMaschen.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Umwandeln des 'loading_state' und der 'wagon_ID' von Strings in numerische Datentypen\n",
    "# String Operationen zum ersetzen der Wörter\n",
    "dfMaschen['loading_state'].replace('Beladen', '1', inplace=True, regex=True)\n",
    "dfMaschen['loading_state'].replace('Leer', '0', inplace=True, regex=True)\n",
    "\n",
    "# Strings werden in integer umgewandelt\n",
    "dfMaschen.loading_state = dfMaschen.loading_state.astype('int64')\n",
    "# Der Movement State wird erst nach einem späteren Preprocessing umgewandelt\n",
    "# dfMaschen.movement_state.astype('float')     #use float, because NaN does not exist in integers\n",
    "\n",
    "print('vorher '+str(len(dfMaschen)))\n",
    "dfMaschen.drop(dfMaschen.loc[dfMaschen['GNSS_velocity'].isna()].index, inplace=True)\n",
    "print('nach NaN GNSS_velocity '+str(len(dfMaschen)))\n",
    "dfMaschen.drop(dfMaschen.loc[dfMaschen['movement_state'].isna()].index, inplace=True)\n",
    "print('nach NaN movement_state '+str(len(dfMaschen)))\n",
    "\n",
    "if False:\n",
    "    # Reihen löschen, in denen der Ladezustand bzw. der Zeitpunkt = 'NaT' sind\n",
    "    dfMaschen.drop(dfMaschen.loc[dfMaschen['loading_state_update']=='NaT'].index, inplace=True)\n",
    "    dfMaschen.drop(dfMaschen.loc[dfMaschen['timestamp_transfer']=='NaT'].index, inplace=True)\n",
    "    dfMaschen.drop(dfMaschen.loc[dfMaschen['timestamp_index']=='NaT'].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5739b295-a34d-49de-8274-62176b4082ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Anwenden der Funktion format_timestamp\n",
    "dfMaschen['loading_state_update'] = dfMaschen['loading_state_update'].apply(format_timestamp) \n",
    "dfMaschen['timestamp_transfer'] = dfMaschen['timestamp_transfer'].apply(format_timestamp) \n",
    "dfMaschen['timestamp_index'] = dfMaschen['timestamp_index'].apply(format_timestamp) \n",
    "# NaT timestamps als NaT belassen im Falle des 'timestamp_measure_movement_state' --> für späteres Vorgehen relevant\n",
    "dfMaschen['timestamp_measure_movement_state'] = dfMaschen['timestamp_measure_movement_state'].apply(lambda x: format_timestamp(x) if x != 'NaT' else 'NaT') \n",
    "\n",
    "# Verwenenden des \"mapping\" files um den \"wagon_type\" und \"wagon_construction\" hinzuzufügen\n",
    "# Hinweis: wenn \"wagon_ID\" nicht im \"mapping\" file wird die Zeile entfernt (--> keine Zuordnung möglich)\n",
    "# Einlesen der mapping pickle Datei\n",
    "mapPath = os.path.join(\"..\", \"..\", \"data\", \"mappingDf.pickle\")\n",
    "dfMapping = pd.read_pickle(mapPath)\n",
    "# Alle NaN Werte droppen\n",
    "# \"provider\" aus dem \"mapping\" DataFrame droppen, da \"provider\" auch schon in dfMaschen vorkommt\n",
    "print(len(dfMapping))\n",
    "dfMapping.drop('provider', axis=1, inplace=True)\n",
    "print(len(dfMapping))\n",
    "dfMapping.reset_index(drop=True, inplace=True)\n",
    "# Verbinden der zwei Tabellen: mapping und dfMaschen nach der gemeinsamen Zeile: wagon_ID\n",
    "dfMaschenMapping = pd.merge(dfMaschen, dfMapping, on = \"wagon_ID\")\n",
    "print(len(dfMaschenMapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9911fd86-f427-40c4-8f4b-a1a434350f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaschenMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207966e-662e-4c25-b89d-7dadd961e308",
   "metadata": {},
   "source": [
    "### Entfernen von spezifischen Werten\n",
    "z.B.:\n",
    "- Geschwindigkeiten von größer > 130 km/h für Güterwagons keine sinnvolle Werte\n",
    "(insbesondere) da im Bahnhof\n",
    "- Höhen, die größer sind als 50 m sind nicht realistisch, da Maschen auf 11 m über N.N,\n",
    "wird aber an dieser Stelle nicht gedroppt, da Altitude aufgrund der hohen Ungenauigkeit und dem geringen (bzw. keinem) Mehrwert nicht verwendet wird\n",
    "(https://www.mapcoordinates.net/de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db953bea-55f8-47d4-802f-8316a1c7205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeilen mit Geschwindigkeiten größer 130 km/h entfernen\n",
    "dfMaschenMapping.drop(dfMaschenMapping[dfMaschenMapping['GNSS_velocity'] > 130].index, inplace=True)\n",
    "dfMaschenMapping.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(len(dfMaschenMapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c10da-867e-41f7-bc71-20f8ceb3506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktionen zum entfernen von Ausreißern (oberhalb 99% Quantil und unterhalb 1% Quantil)\n",
    "# Aufspüren der Grenzen von Ausreißern für eine bestimmte Variable in einem DataFrame\n",
    "def outlierThresholds(dataframe, variable):\n",
    "    quartile1 = dataframe[variable].quantile(0.01)\n",
    "    quartile3 = dataframe[variable].quantile(0.99)\n",
    "    interquantileRange = quartile3 - quartile1\n",
    "    upLimit = quartile3 + 1.5 * interquantileRange\n",
    "    lowLimit = quartile1 - 1.5 * interquantileRange\n",
    "    return lowLimit, upLimit\n",
    "\n",
    "# Funktion, bei der Werte ober-/unterhalb der Quantile mit dem entsprechenden\n",
    "# Quantilwert ersetzt werden\n",
    "def replaceWithThresholds(dataframe, variable):\n",
    "    lowLimit, upLimit = outlierThresholds(dataframe, variable)\n",
    "    dataframe.loc[(dataframe[variable] < lowLimit), variable] = lowLimit\n",
    "    dataframe.loc[(dataframe[variable] > upLimit), variable] = upLimit\n",
    "    \n",
    "# Funktion, bei der Werte ober-/unterhalb der Quantile gelöscht werden\n",
    "def removeThresholds(dataframe, variable):\n",
    "    lowLimit, upLimit = outlierThresholds(dataframe, variable)\n",
    "    dataframe.drop(dataframe[dataframe[variable] < lowLimit].index, inplace=True)\n",
    "    dataframe.drop(dataframe[dataframe[variable] > upLimit].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666672d3-cde7-439b-b4a6-a4da25f8bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwendung auf sinnvolle Spalten/Variablen\n",
    "listToRemoveTresholds = [\"signal_quality_satellite\",\n",
    "                         \"signal_quality_hdop\",\n",
    "                         \"GNSS_velocity\",           # Anmerkung: muss diskutiert werden\n",
    "                         ]\n",
    "# Variablen betrachten mit: dfMaschenMapping.columns\n",
    "\n",
    "# Achtung: nur einmalige Anwendung!\n",
    "for var in listToRemoveTresholds:\n",
    "    removeThresholds(dfMaschenMapping, var)\n",
    "print(len(dfMaschenMapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a875a2-433b-47c8-ab93-6d7c5e393f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMaschenMapping.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf5efd7-0a05-41cb-b197-ccf1da1eaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "safePath = os.path.join(\"..\", \"..\", \"data\", \"maschenPickled.pickle\")\n",
    "dfMaschenMapping.to_pickle(safePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96f81a3-0dde-4198-9494-85deb759ecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb254f58-0bbe-4f5d-8d1d-912a49587378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad832574-357d-45f3-887d-d593ac52a993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87435518-f155-418f-82da-3e28991625e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f6f7c-7cbf-4b44-a859-00316b0d4ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ed070-f8d1-41ef-94e2-1712702225f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b7c20-a74a-4fc4-894b-36be7f2a05ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dad48-89f5-41b9-9faa-3125fa7925d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e21a9-6509-4886-9325-a3642002585a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe60ac-27e8-4b56-b750-39c10dc1835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f7e2e-6302-44b1-a60d-77759ce77359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba6896-aadf-4c00-818b-d025f8d3f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ac8e7-18c7-4f4c-8b12-e3c4ba55709f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadb0f9-03d5-475d-92cb-00029ac6f18e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b167a3-71e8-4967-8572-90cad0d9638a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f526644d-cec2-45fa-a319-bb0acd7db56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece28e92-dcb5-4e0b-896d-a9a16b9958ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
