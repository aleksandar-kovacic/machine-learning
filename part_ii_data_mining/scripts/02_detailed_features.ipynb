{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features\n",
    "feature| GPS |mobile network|\n",
    "---|:----:|:---------:|\n",
    "latency|---|timestamp_index - timestamp_transfer|\n",
    "coverage|position_determination |if data is cached before it is send, no connection is available|\n",
    "quality|signal_quality_satellite|signal_quality_hdop|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = join('..', '..', 'data', 'TUDA_data', 'all_TUDA_data.parquet')\n",
    "df = pd.read_parquet(parquet_path, \n",
    "                     columns=[\n",
    "                         \"timestamp_index\", \"timestamp_transfer\", \"timestamp_measure_position\", \n",
    "                         \"determination_position\", \"latitude\", \"longitude\", \"loading_state\", \n",
    "                         \"signal_quality_satellite\", \"signal_quality_hdop\"\n",
    "                     ]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latency'] = df.timestamp_index - df.timestamp_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coverage: \n",
    "**GPS**: binÃ¤r, als Indikator position determination nehmen\n",
    "+ wenn position_determination = 1 -> covered (1)\n",
    "+ wenn position determination = 4 -> not covered(0)\n",
    "\n",
    "**mobile**: als Indikator Dauer der Zwischenspeicherung nehmen\n",
    "+ Zwischenspeicherung: timestamp_transfer - timestamp_measure_position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coverage_gps'] = df.determination_position == 1\n",
    "df.coverage_gps.replace({True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coverage_mobile'] = df.timestamp_transfer - df.timestamp_measure_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[['determination_position', 'latency', 'coverage_gps', 'coverage_mobile', \n",
    "                  'signal_quality_satellite', 'signal_quality_hdop']].copy()\n",
    "corrMatrix = df_features.corr()\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "sn.heatmap(corrMatrix, annot=True)\n",
    "output_path = join('..', 'output')\n",
    "fig.savefig(join(output_path, 'features_correlation.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relative Standardabweichung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_rel = (df_features.std() / df_features.mean()).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(df_features.columns,std_rel)\n",
    "plt.title('relative standard deviation')\n",
    "plt.grid(axis='y')\n",
    "fig.savefig(join(output_path, 'features_std.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_errs = []\n",
    "std_errs_rel = []\n",
    "for feature in df_features.columns:\n",
    "    clean_feature = df_features[feature].dropna()\n",
    "    std_err = clean_feature.std() / len(clean_feature)\n",
    "    std_errs.append(std_err)\n",
    "    std_errs_rel.append(std_err/clean_feature.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(df_features.columns,std_errs)\n",
    "plt.title('standard error')\n",
    "plt.grid(axis='y')\n",
    "fig.savefig(join(output_path, 'features_std_error.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 3))\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(df_features.columns,std_errs_rel)\n",
    "plt.title('relative standard error')\n",
    "plt.grid(axis='y')\n",
    "fig.savefig(join(output_path, 'features_std_error_rel.png'), dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from scipy.stats import t\n",
    "\n",
    "def get_statistics(x: iter) -> tuple:\n",
    "    \"\"\"\n",
    "    calculate mean and standard deviation of an iterable\n",
    "    \"\"\"\n",
    "    mean = np.mean(x)\n",
    "    stddev = np.std(x)\n",
    "    return mean, stddev\n",
    "\n",
    "\n",
    "def get_correlation_coefficient(x: iter, y: iter) -> float:\n",
    "    \"\"\"\n",
    "    calculate correlation coefficient of two iterables of the same lengths\n",
    "    \"\"\"\n",
    "    x_mean, x_stddev = get_statistics(x)\n",
    "    y_mean, y_stddev = get_statistics(y)\n",
    "    sum_products = 0\n",
    "    for xi, yi in zip(x, y):\n",
    "        sum_products += (xi - x_mean) * (yi - y_mean)\n",
    "    s_xy = 1 / (len(x) - 1) * sum_products\n",
    "    return s_xy / (x_stddev * y_stddev)\n",
    "\n",
    "\n",
    "def correlation_test(x, y):\n",
    "    # make sure that x and y have same length:\n",
    "    len_min = min((len(x), len(y)))\n",
    "    x = x[:len_min]\n",
    "    y = y[:len_min]\n",
    "    r_xy = get_correlation_coefficient(x, y)\n",
    "    if abs(r_xy - 1) < 1e-6:\n",
    "        r_xy = int(r_xy)\n",
    "        p_value = 0.0\n",
    "    else:\n",
    "        t_score = r_xy * np.sqrt(len_min - 2) / np.sqrt(1 - r_xy ** 2)\n",
    "        p_value = t.sf(abs(t_score), len_min - 2) * 2\n",
    "    if p_value < 0.05:\n",
    "        correlated = True\n",
    "    else:\n",
    "        correlated = False\n",
    "    return correlated, p_value, r_xy'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation_test(df_features.dropna(subset=['signal_quality_hdop']).signal_quality_hdop.to_numpy(), df_features.dropna(subset=['signal_quality_hdop']).coverage_mobile.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"n_features = len(df_features.columns)\n",
    "correlation_mat = np.zeros((n_features, n_features))\n",
    "for i, col_i in enumerate(df_features.columns):\n",
    "    for j, col_j in enumerate(df_features.columns):\n",
    "        if i >= j:\n",
    "            correlated, _, corrcoef = correlation_test(df_features[col_i], df_features[col_j])\n",
    "            # check NaN\n",
    "            if corrcoef == corrcoef:\n",
    "                # use symmetry of correlation matrix\n",
    "                correlation_mat[i, j] = corrcoef\n",
    "                correlation_mat[j, i] = corrcoef\n",
    "            else:\n",
    "                print(\"i: %s, j: %s\" %(col_i, col_j))\n",
    "                #correlated, _, corrcoef = correlation_test(df_features.dropna(subset=['col_i,'])[col_i], df_features.dropna()[col_j])\n",
    "            if not correlated:\n",
    "                correlation_mat[i, j] = np.nan\n",
    "                correlation_mat[j, i] = np.nan\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sn.heatmap(correlation_mat, vmin=-1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
